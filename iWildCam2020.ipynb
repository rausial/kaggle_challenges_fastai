{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.data.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai4kaggle.data import *\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "input_path = Path('/storage/iwildcam-2020-fgvc7')\n",
    "my_data_path = Path('/storage/my-iwildcam2020-data')\n",
    "models_path = Path(my_data_path/'resnet50_checkpoints/test/models')\n",
    "use_previous_model = True\n",
    "model = resnet50\n",
    "n_epochs = 1\n",
    "kaggle_msg = f\"resnet50, {n_epochs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verified_image_files(path):\n",
    "    \n",
    "    if Path(my_data_path/'image_paths.pkl').exists():\n",
    "        with open(my_data_path/'image_paths.pkl', 'rb') as f:\n",
    "            files = pickle.load(f)\n",
    "    else:\n",
    "        files = get_image_files(path)\n",
    "        with open(my_data_path/'image_paths.pkl', 'wb') as f:\n",
    "            pickle.dump(files, f)\n",
    "        \n",
    "    blacklist = []\n",
    "    \n",
    "    if (path/'failed_imgs_lst.pkl').exists():\n",
    "        with open(path/'failed_imgs_lst.pkl', 'rb') as f:\n",
    "            blacklist = pickle.load(f)\n",
    "    else:\n",
    "        blacklist = verify_images(files)\n",
    "        with open(path/'failed_imgs_lst.pkl', 'wb') as f:\n",
    "            pickle.dump(blacklist, f)\n",
    "\n",
    "\n",
    "    return list(set(files).difference(blacklist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_iwildcam(fname, prefix=None):\n",
    "    \"Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.\"\n",
    "    \n",
    "    annot_dict = json.load(open(fname))\n",
    "    id2images, id2cats = {}, {}\n",
    "    classes = {o['id']:o['name'] for o in annot_dict['categories']}\n",
    "    id2cats = {o['image_id']:o['category_id'] for o in annot_dict['annotations']}        \n",
    "    id2images = {o['id']:o['file_name'] for o in annot_dict['images']}\n",
    "                                     \n",
    "    ids = list(id2images.keys())\n",
    "    return [id2images[k] for k in ids], [id2cats[k] for k in ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, lbls = get_annotations_iwildcam(input_path/'iwildcam2020_train_annotations.json')\n",
    "# img2lbls = dict(zip(images, lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_counts(img_labels):\n",
    "    label_counts = {}\n",
    "    \n",
    "    lbls_list = img_labels\n",
    "    classes = list(set(lbls_list))\n",
    "\n",
    "    for clss in classes:\n",
    "        imgs_class = [i for i, v in enumerate(lbls_list) if v == clss]\n",
    "        label_counts[clss] = len(imgs_class)\n",
    "        \n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_label_images(path, min_count=2):\n",
    "    image_files = get_verified_image_files(path)\n",
    "    freq_image_files = []\n",
    "    images, lbls = get_annotations_iwildcam(input_path/'iwildcam2020_train_annotations.json')\n",
    "    img2lbls = dict(zip(images, lbls))\n",
    "    \n",
    "    label_counts = get_label_counts(lbls)\n",
    "    \n",
    "    for img in image_files:\n",
    "        lbl = img2lbls[img.name][0]\n",
    "        if label_counts[lbl] >= min_count:\n",
    "            freq_image_files.append(img)\n",
    "    \n",
    "    return freq_image_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_df(annotation_file, outputs_path, min_cat_count=2):\n",
    "    images, lbls = get_annotations_iwildcam(annotation_file)\n",
    "    img2lbls = dict(zip(images, lbls))\n",
    "    \n",
    "    if not outputs_path.exists():\n",
    "        outputs_path.mkdir()\n",
    "        \n",
    "    label_counts = get_label_counts(lbls)\n",
    "    if Path(outputs_path/'image_paths.pkl').exists():\n",
    "        with open(outputs_path/'image_paths.pkl', 'rb') as f:\n",
    "            image_files = pickle.load(f)\n",
    "    else:\n",
    "        image_files = get_image_files(input_path/'train')\n",
    "        with open(outputs_path/'image_paths.pkl', 'wb') as f:\n",
    "            pickle.dump(image_files, f)\n",
    "\n",
    "    if (outputs_path/'failed_imgs_lst.pkl').exists():\n",
    "        with open(outputs_path/'failed_imgs_lst.pkl', 'rb') as f:\n",
    "            blacklist = pickle.load(f)\n",
    "    else:\n",
    "        blacklist = verify_images(image_files)\n",
    "        with open(outputs_path/'failed_imgs_lst.pkl', 'wb') as f:\n",
    "            pickle.dump(blacklist, f)\n",
    "\n",
    "    image_files = set(image_files).difference(blacklist)\n",
    "    \n",
    "    rare_label_images = []\n",
    "    for img in image_files:\n",
    "        lbl = img2lbls[img.name]\n",
    "        if label_counts[lbl] < min_cat_count:\n",
    "            rare_label_images.append(img)\n",
    "            \n",
    "    image_files = image_files.difference(rare_label_images)\n",
    "    \n",
    "    train_dict = {'file': [], 'category': []}\n",
    "    for img in image_files:\n",
    "        train_dict['file'].append(img.name)\n",
    "        train_dict['category'].append(img2lbls[img.name])\n",
    "        \n",
    "    return pd.DataFrame(train_dict)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_train_df(input_path/'iwildcam2020_train_annotations.json',\n",
    "                        my_data_path, min_cat_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_x=ColReader(0, pref=input_path/\"train\"),\n",
    "    get_y=ColReader(1),\n",
    "    item_tfms=Resize(800),\n",
    "    batch_tfms=aug_transforms(size=460),\n",
    "    splitter=RandomSplitter(valid_pct=0.025, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = db.dataloaders(train_df, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_test_images(path, outputs_path):\n",
    "    image_files = get_image_files(path)\n",
    "    \n",
    "    if (outputs_path/'failed_test_imgs_lst.pkl').exists():\n",
    "        with open(outputs_path/'failed_test_imgs_lst.pkl', 'rb') as f:\n",
    "            blacklist = pickle.load(f)\n",
    "    else:\n",
    "        blacklist = verify_images(image_files)\n",
    "        with open(outputs_path/'failed_test_imgs_lst.pkl', 'wb') as f:\n",
    "            pickle.dump(blacklist, f)\n",
    "\n",
    "    image_files = set(image_files).difference(blacklist)\n",
    "    \n",
    "    return list(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardTrainEvalCallback(TrainEvalCallback):\n",
    "    \"`Callback` that skips to a given epoch the number of iterations done and properly sets training/eval mode\"\n",
    "    run_valid = False\n",
    "    def after_create(self): self.learn.n_epoch = 1\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Set the iter and epoch counters to 0, put the model and the right device\"\n",
    "        self.learn.epoch,self.learn.loss = 0,tensor(0.)\n",
    "        self.learn.train_iter,self.learn.pct_train = 0,0.\n",
    "        if hasattr(self.dls, 'device'): self.model.to(self.dls.device)\n",
    "        if hasattr(self.model, 'reset'): self.model.reset()\n",
    "\n",
    "    def after_batch(self):\n",
    "        \"Update the iter counter (in training mode)\"\n",
    "        self.learn.pct_train += 1./(self.n_iter*self.n_epoch)\n",
    "        self.learn.train_iter += 1\n",
    "\n",
    "    def before_train(self):\n",
    "        \"Set the model in training mode\"\n",
    "        dd\n",
    "        self.model.train()\n",
    "        self.learn.training=True\n",
    "\n",
    "    def before_validate(self):\n",
    "        \"Set the model in validation mode\"\n",
    "        self.model.eval()\n",
    "        self.learn.training=False\n",
    "        \n",
    "class SkipToEpoch(Callback):\n",
    "    def __init__(self, s_epoch, n_epoch): \n",
    "        self.s_epoch = s_epoch\n",
    "        \n",
    "    def before_fit(self):\n",
    "        \"Set the iter and epoch counters, put the model and the right device\"\n",
    "\n",
    "        self.learn.train_iter, self.learn.pct_train = self.skip_to_epoch, self.skip_to_epoch / self.n_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_fine_tune(dls, model, metrics, path, path_to_model, n_epochs):\n",
    "    learn = cnn_learner(dls, model, metrics=metrics, path=path)    \n",
    "    learn.load(path_to_model/'model')\n",
    "    \n",
    "    lr_min, lr_steep = learn.lr_find()\n",
    "    learn.fine_tune(n_epochs, lr_steep, cbs=SaveModelCallback(with_opt=True))\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(learn, test_images):\n",
    "    test_dl = learn.dls.test_dl(test_images)\n",
    "    preds_batch, _, dec_preds = learn.get_preds(dl=test_dl, with_decoded=True)\n",
    "    dec_cats = [learn.dls.vocab[dec_pred] for dec_pred in dec_preds]\n",
    "    \n",
    "    img_names = [img.stem for img in test_images]\n",
    "    test_results = pd.DataFrame({'Id': img_names, 'Category': dec_cats})\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_previous_model:\n",
    "    learn = restart_fine_tune(dls, resnet50, accuracy, my_data_path/'resnet50_checkpoints/test', models_path, n_epochs)\n",
    "else:\n",
    "    learn = cnn_learner(dls, resnet50, metrics=accuracy, path=models_path)\n",
    "    lr_min,lr_steep = learn.lr_find()\n",
    "    learn.fine_tune(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = get_valid_test_images(input_path/'test', my_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = predict_batch(learn, test_images)\n",
    "test_results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c iwildcam-2020-fgvc7 -f \"submission.csv\" -m {kaggle_msg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, nrows=3, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = Path()\n",
    "# learn = load_learner(path/'export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 2\n",
    "pred,pred_idx,probs = learn.predict(test_images[img_idx])\n",
    "img = PILImage.create(test_images[img_idx])\n",
    "\n",
    "img.show()\n",
    "print(f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annot_dict = json.load(open('/storage/iwildcam-2020-fgvc7/iwildcam2020_train_annotations.json'))\n",
    "annot_dict['categories']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
